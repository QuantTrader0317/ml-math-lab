# ğŸ§  Machine Learning Math Lab â€” 5 Core Projects in Python (Built from Scratch)

### ğŸš€ Overview
This project is my hands-on lab for mastering the **mathematical foundations of machine learning** using pure Python (v3.13) and NumPy.

Everything here was written, debugged, and explained line by line inside **PyCharm**, to fully understand *how* the math behind each model actually works â€” not just how to call it from a library.

---

## ğŸ“‚ Projects Included

| # | Project | Core Concept | Key Skill |
|:-:|:--|:--|:--|
| 1 | **Power Iteration** | Eigenvalues & Eigenvectors | Linear Algebra Fundamentals |
| 2 | **Ordinary Least Squares (OLS)** | Linear Regression | Matrix Inversion & RÂ² Analysis |
| 3 | **Logistic Regression (Gradient Descent)** | Classification | Optimization & Cost Functions |
| 4 | **k-Means Clustering** | Unsupervised Learning | Distance Metrics & Iterative Refinement |
| 5 | **Principal Component Analysis (PCA)** | Dimensionality Reduction | SVD, Variance, & Reconstruction |

---

## ğŸ’¡ What I Learned
- How to **translate math formulas into working code**  
- Why each algorithm converges (or fails)  
- The difference between **exact math** and **numerical stability**  
- How modern libraries like scikit-learn are built under the hood  

---

## âš™ï¸ Tools Used
- **Python 3.13**
- **NumPy 2.1+**
- **scikit-learn** (for cross-verification)
- **PyCharm** (for daily environment setup, debugging, and testing)

---

## ğŸ§© Example Insights
- **Power Iteration:** the matrix naturally â€œpullsâ€ vectors toward its strongest direction  
- **OLS Regression:** the math behind line-fitting is just solving `Xáµ€XÎ² = Xáµ€y`  
- **Logistic Regression:** prediction is probability, not just classification  
- **k-Means:** unsupervised patterns form through repeated nearest-center assignments  
- **PCA:** you can compress data without losing most of its meaning

---

## ğŸ Key Takeaway
> â€œIf you can code the math from scratch, you can understand any ML model â€” no black boxes.â€

This repo built my foundation for deeper research in **quantitative finance, econometrics, and machine learning**.

---

## ğŸ“¸ Optional Demo Post
> Just finished building 5 core ML algorithms completely from scratch in Python.  
> No high-level wrappers, no shortcuts â€” just math, NumPy, and logic.  
> The goal wasnâ€™t just to get the right answer, but to *understand* why itâ€™s right.  
>
> ğŸ§® Power Iteration â†’ Eigenvalues  
> ğŸ“ˆ OLS Regression â†’ Linear Models  
> ğŸ” Logistic Regression â†’ Optimization  
> ğŸ¯ k-Means â†’ Clustering  
> ğŸ” PCA â†’ Dimensionality Reduction  
>
> All coded and explained inside PyCharm using Python 3.13.  
> This is how you turn theory into intuition.

---

### ğŸ“ Folder Layout
ml-math-lab/
â”‚
â”œâ”€â”€ projects/
â”‚ â”œâ”€â”€ 1_power_iteration.py
â”‚ â”œâ”€â”€ 2_ols_from_scratch.py
â”‚ â”œâ”€â”€ 3_logreg_scratch.py
â”‚ â”œâ”€â”€ 4_kmeans_scratch.py
â”‚ â””â”€â”€ 5_pca_svd.py
â”‚
â”œâ”€â”€ README.md â† this file
â””â”€â”€ requirements.txt

---

### âœ… Next Step Ideas
- Ridge & Lasso Regression (regularized OLS)
- PCA Whitening / Eigen Decomposition
- Gradient Descent Variants (Adam, Momentum)
- Factor Models & Quant Applications

---

**Created by:** Clyde Williams Jr.  
**Focus:** Quantitative Finance â€¢ Machine Learning â€¢ Mathematical Research  
**Stack:** Python | NumPy | Statistics | Linear Algebra
